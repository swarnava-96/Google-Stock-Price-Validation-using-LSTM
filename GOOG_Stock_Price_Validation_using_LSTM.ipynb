{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GOOG Stock Price Validation using LSTM",
      "provenance": [],
      "mount_file_id": "1V-4WsD9WFX-SLHfYLaGCWfjRjd3n6SPI",
      "authorship_tag": "ABX9TyOthIZnzwe3EQsKTRuhEzQ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarnava-96/Google-Stock-Price-Validation-using-LSTM/blob/main/GOOG_Stock_Price_Validation_using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w5yenBLn0ka"
      },
      "source": [
        "# **GOOG Stock Price Validation using LSTM**\n",
        "\n",
        "In this project I will check how LSTMs work on predicting stock prices. I will take the \"GOOG\" stock prices for the entire year of 2016 as my training data and I will predict the stock prices for the month of January, 2017. The test data contains the actual stock prices for January 2017. The goal is to verify how well LSTM performs as I already know the actual stock prices for January, 2017. The dataset was collected from Yahoo Finance. Here, I will consider the feature \"Open\" and based on that, I will predict and validate.\n",
        "\n",
        "### Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZD2etjloKb0",
        "outputId": "1327d7bc-82a2-44e5-c1b6-b7708db49bd0"
      },
      "source": [
        "cd \"/content/drive/MyDrive/Data\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd0FSEX9oVZe"
      },
      "source": [
        "# Importing the necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QXjuS6jommU"
      },
      "source": [
        "### Loading the Training Data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "sU0IZdwkolPv",
        "outputId": "0924bc1e-03d6-4ccd-9303-2d5d35f66e4a"
      },
      "source": [
        "dataset_train = pd.read_csv(\"Google_Stock_Price_Train.csv\")\n",
        "dataset_train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/3/2012</td>\n",
              "      <td>325.25</td>\n",
              "      <td>332.83</td>\n",
              "      <td>324.97</td>\n",
              "      <td>663.59</td>\n",
              "      <td>7,380,500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/4/2012</td>\n",
              "      <td>331.27</td>\n",
              "      <td>333.87</td>\n",
              "      <td>329.08</td>\n",
              "      <td>666.45</td>\n",
              "      <td>5,749,400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/5/2012</td>\n",
              "      <td>329.83</td>\n",
              "      <td>330.75</td>\n",
              "      <td>326.89</td>\n",
              "      <td>657.21</td>\n",
              "      <td>6,590,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/6/2012</td>\n",
              "      <td>328.34</td>\n",
              "      <td>328.77</td>\n",
              "      <td>323.68</td>\n",
              "      <td>648.24</td>\n",
              "      <td>5,405,900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/9/2012</td>\n",
              "      <td>322.04</td>\n",
              "      <td>322.29</td>\n",
              "      <td>309.46</td>\n",
              "      <td>620.76</td>\n",
              "      <td>11,688,800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date    Open    High     Low   Close      Volume\n",
              "0  1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
              "1  1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
              "2  1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
              "3  1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
              "4  1/9/2012  322.04  322.29  309.46  620.76  11,688,800"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "m2z04tTGo6U4",
        "outputId": "bb13a73f-3b73-450a-e544-5e4a109eae28"
      },
      "source": [
        "# Lets see the last 5 records\n",
        "\n",
        "dataset_train.tail()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>12/23/2016</td>\n",
              "      <td>790.90</td>\n",
              "      <td>792.74</td>\n",
              "      <td>787.28</td>\n",
              "      <td>789.91</td>\n",
              "      <td>623,400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>12/27/2016</td>\n",
              "      <td>790.68</td>\n",
              "      <td>797.86</td>\n",
              "      <td>787.66</td>\n",
              "      <td>791.55</td>\n",
              "      <td>789,100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>12/28/2016</td>\n",
              "      <td>793.70</td>\n",
              "      <td>794.23</td>\n",
              "      <td>783.20</td>\n",
              "      <td>785.05</td>\n",
              "      <td>1,153,800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>12/29/2016</td>\n",
              "      <td>783.33</td>\n",
              "      <td>785.93</td>\n",
              "      <td>778.92</td>\n",
              "      <td>782.79</td>\n",
              "      <td>744,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>12/30/2016</td>\n",
              "      <td>782.75</td>\n",
              "      <td>782.78</td>\n",
              "      <td>770.41</td>\n",
              "      <td>771.82</td>\n",
              "      <td>1,770,000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date    Open    High     Low   Close     Volume\n",
              "1253  12/23/2016  790.90  792.74  787.28  789.91    623,400\n",
              "1254  12/27/2016  790.68  797.86  787.66  791.55    789,100\n",
              "1255  12/28/2016  793.70  794.23  783.20  785.05  1,153,800\n",
              "1256  12/29/2016  783.33  785.93  778.92  782.79    744,300\n",
              "1257  12/30/2016  782.75  782.78  770.41  771.82  1,770,000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aLIQfQl5NSW",
        "outputId": "09a3c079-9744-4376-f9d0-98b606bbd96c"
      },
      "source": [
        "# Lets see the shape of the dataset\n",
        "\n",
        "dataset_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V9GwrhMpBTe",
        "outputId": "a69354b7-a3fa-42ca-fa96-d9fd7cd0a1b4"
      },
      "source": [
        "# Lets take the feature \"Open\" for our further analysis\n",
        "\n",
        "training_set = dataset_train.iloc[:, 1:2].values\n",
        "training_set"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[325.25],\n",
              "       [331.27],\n",
              "       [329.83],\n",
              "       ...,\n",
              "       [793.7 ],\n",
              "       [783.33],\n",
              "       [782.75]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43f3feSermdl"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx0TpY6_rSyM"
      },
      "source": [
        "# Feature Scaling\n",
        "\n",
        "# Importing Sklearn's MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Initializing MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "\n",
        "# Fitting and transforming the train data\n",
        "training_set_scaled = scaler.fit_transform(training_set)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvRxva1_s5-f",
        "outputId": "e5fb6c12-b6f3-469e-bdf8-9fb2ebe3c635"
      },
      "source": [
        "# lets see the length of training_set_scaled\n",
        "\n",
        "len(training_set_scaled)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1258"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx3Z2u22sYp5"
      },
      "source": [
        "# Creating a data structure with 60 time steps and 1 output\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(60, len(training_set_scaled)):\n",
        "  X_train.append(training_set_scaled[i - 60 : i,0])\n",
        "  y_train.append(training_set_scaled[i, 0])\n",
        "\n",
        "# Converting the lists X_train, y_train into arrays\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo_xGw5-uRJS"
      },
      "source": [
        "# Reshaping the two dimensional array X_train into 3D as LSTM requires that\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OS7J7GBu3BG"
      },
      "source": [
        "### Building the RNN LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5aGkYhfuq9R",
        "outputId": "fba4e1cf-1e3e-4394-f9c6-15409442c298"
      },
      "source": [
        "# Importing tensorflow version 2.5.0\n",
        "\n",
        "!pip install tensorflow==2.5"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.5 in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (0.12.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (3.17.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (2.5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (3.1.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.34.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (2.6.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (0.37.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (0.2.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (57.4.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (1.34.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (0.4.5)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYfVf9eJzBuP"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FLfU5QEWzTlU",
        "outputId": "ec580c82-a3dd-42c3-8faf-4e9b066c7e11"
      },
      "source": [
        "# Lets check the version\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQrRIO03vEp9"
      },
      "source": [
        "# Importing the Keras library and packages\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_psaNmitxj1Z"
      },
      "source": [
        "# Initializing the RNN\n",
        "\n",
        "regressor = Sequential()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvblKwwXzpGZ"
      },
      "source": [
        "# Adding the first LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding the second LSTM layer and some Dropout regularization\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding the third LSTM layer and some Dropout regularization\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a fourth LSTM layer and some Droput\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding the Output layer\n",
        "regressor.add(Dense(units = 1))\n",
        "\n",
        "# Compiling the RNN\n",
        "regressor.compile(optimizer = \"adam\", loss = \"mean_squared_error\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt_ZdAAG1Mt2",
        "outputId": "b9696c70-eeb7-453f-ff0f-3e47a065e01a"
      },
      "source": [
        "# Lets see the model summary\n",
        "\n",
        "regressor.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 60, 50)            10400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 50)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 60, 50)            20200     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 60, 50)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 60, 50)            20200     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 60, 50)            0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 71,051\n",
            "Trainable params: 71,051\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKMbm8NW1rOI",
        "outputId": "da01eff2-c3c3-4090-eb14-ddf82382ce36"
      },
      "source": [
        "# Fitting the RNN to the training dataset\n",
        "\n",
        "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 11s 117ms/step - loss: 0.0345\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0061\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0058\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0063\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0053\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0051\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0045\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0051\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0049\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0042\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0053\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0044\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0043\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0045\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.0034\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0035\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.0035\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0038\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.0034\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.0037\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0034\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0034\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0031\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.0031\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.0033\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.0028\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0032\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.0031\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0033\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 4s 112ms/step - loss: 0.0031\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0030\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0027\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0031\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0030\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0029\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0027\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0028\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0024\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.0024\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0027\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0028\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0027\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 5s 118ms/step - loss: 0.0022\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0026\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0025\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0026\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0027\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0026\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0026\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0024\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 5s 122ms/step - loss: 0.0022\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.0023\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0022\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0021\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0021\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0024\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0023\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.0020\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 5s 118ms/step - loss: 0.0022\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0022\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0024\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0024\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0022\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0020\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0019\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0021\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0019\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0021\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0018\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 4s 113ms/step - loss: 0.0018\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0020\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0019\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0018\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0017\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0019\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0018\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0017\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0019\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0017\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0016\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0017\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0017\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0018\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0020\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 4s 114ms/step - loss: 0.0017\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0015\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0017\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0016\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0015\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0016\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0014\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 5s 118ms/step - loss: 0.0016\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0016\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 5s 120ms/step - loss: 0.0015\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0016\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 5s 119ms/step - loss: 0.0016\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 4s 118ms/step - loss: 0.0015\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 4s 116ms/step - loss: 0.0015\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 4s 115ms/step - loss: 0.0016\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 4s 117ms/step - loss: 0.0016\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f33b21821d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaUwSoWK4ok2"
      },
      "source": [
        "### Getting the predicted stock price of 2017"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "cXopjBPD18NK",
        "outputId": "833dc4cb-cfa5-4885-8ce1-be53448f8620"
      },
      "source": [
        "# Loading the test dataset\n",
        "\n",
        "dataset_test = pd.read_csv(\"Google_Stock_Price_Test.csv\")\n",
        "dataset_test.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/3/2017</td>\n",
              "      <td>778.81</td>\n",
              "      <td>789.63</td>\n",
              "      <td>775.80</td>\n",
              "      <td>786.14</td>\n",
              "      <td>1,657,300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/4/2017</td>\n",
              "      <td>788.36</td>\n",
              "      <td>791.34</td>\n",
              "      <td>783.16</td>\n",
              "      <td>786.90</td>\n",
              "      <td>1,073,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/5/2017</td>\n",
              "      <td>786.08</td>\n",
              "      <td>794.48</td>\n",
              "      <td>785.02</td>\n",
              "      <td>794.02</td>\n",
              "      <td>1,335,200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/6/2017</td>\n",
              "      <td>795.26</td>\n",
              "      <td>807.90</td>\n",
              "      <td>792.20</td>\n",
              "      <td>806.15</td>\n",
              "      <td>1,640,200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/9/2017</td>\n",
              "      <td>806.40</td>\n",
              "      <td>809.97</td>\n",
              "      <td>802.83</td>\n",
              "      <td>806.65</td>\n",
              "      <td>1,272,400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date    Open    High     Low   Close     Volume\n",
              "0  1/3/2017  778.81  789.63  775.80  786.14  1,657,300\n",
              "1  1/4/2017  788.36  791.34  783.16  786.90  1,073,000\n",
              "2  1/5/2017  786.08  794.48  785.02  794.02  1,335,200\n",
              "3  1/6/2017  795.26  807.90  792.20  806.15  1,640,200\n",
              "4  1/9/2017  806.40  809.97  802.83  806.65  1,272,400"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLXnTUfQ5GwK",
        "outputId": "24ba5c87-de41-4867-f9c2-e7d949fa4e28"
      },
      "source": [
        "# Lets see the shape of the test data\n",
        "\n",
        "dataset_test.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOT7l55R5toB"
      },
      "source": [
        "# Lets concatenate the train and test data\n",
        "\n",
        "dataset_total = pd.concat((dataset_train[\"Open\"], dataset_test[\"Open\"]), axis = 0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEGDEHAh-C6A"
      },
      "source": [
        "# Lets take the \"Open\" fetaure for prediction as we trained our model on the \"Open\" feature itself\n",
        "real_stock_price = dataset_test.iloc[:, 1:2].values"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlXwNyy96tht"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60 :].values\n",
        "\n",
        "inputs = inputs.reshape(-1,1)\n",
        "\n",
        "inputs = scaler.transform(inputs)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj2TqwoK8Dp2",
        "outputId": "c022f445-839a-49e7-ca88-1c342a97565d"
      },
      "source": [
        "# lets see the length of inputs \n",
        "\n",
        "len(inputs)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1RQ7Z_o7t0L"
      },
      "source": [
        "# Creating a data structure with 60 time steps and 1 output\n",
        "X_test = []\n",
        "\n",
        "for i in range(60, len(inputs)):\n",
        "  X_test.append(inputs[i - 60 : i, 0])\n",
        "\n",
        "# Lets convert the list X_test into array\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Reshaping into 3D\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71iE3mHE8_yI"
      },
      "source": [
        "# Prediction\n",
        "\n",
        "predicted_stock_price = regressor.predict(X_test)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GoDzvv59Luv"
      },
      "source": [
        "# Inverse transforming the data\n",
        "\n",
        "predicted_stock_price = scaler.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "aSYGnvRt9aKB",
        "outputId": "5bf168a4-ef22-414a-9ea5-67510b815740"
      },
      "source": [
        "# Lets visualize and validate the actual VS predicted stock prices\n",
        "\n",
        "plt.plot(real_stock_price, color = \"red\", label = \"Real Google Stock Price\")\n",
        "plt.plot(predicted_stock_price, color = \"blue\", label = \"Predicted Google Stock Price\")\n",
        "plt.title(\"Google Stock Price Validation\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Google Stock Price\")\n",
        "plt.legend()\n",
        "plt.show();"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPi4ryluBi2O"
      },
      "source": [
        "We can conclude that the model worked very well. Though getting the exact values is beyond our scope but the model captured the trend well."
      ]
    }
  ]
}